{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Snapshot_ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jaysgmoWzAc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input ,Concatenate,Add\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization,Activation\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,DepthwiseConv2D,MaxPool2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras import backend\n",
        "from math import pi\n",
        "from math import cos\n",
        "from math import floor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jgnw0TpdwSE",
        "outputId": "49e8d38a-d5de-4776-cc7f-575fae5d75c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvSmvaQxYS5w"
      },
      "source": [
        "img_h,img_w= (200,200)\n",
        "batch_size=16\n",
        "dirr=r\"./Binarised data\"\n",
        "\n",
        "\n",
        "n_epochs = 500\n",
        "n_cycles = n_epochs / 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF4obF1ZQNES"
      },
      "source": [
        "def test_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), input_shape=(img_h,img_w,1)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(8, activation='softmax'))\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE9mAL2OW5PA"
      },
      "source": [
        "def Residual_Unit(input_tensor, nb_of_input_channels, max_dilation, number_of_units):\n",
        "    \n",
        "  for i in range(number_of_units):\n",
        "    x1 = Conv2D(nb_of_input_channels*2, \n",
        "                kernel_size = (1,1),\n",
        "                strides = (1,1), padding='same', \n",
        "                dilation_rate= (1,1), activation='relu')(input_tensor)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "  \n",
        "    a = []\n",
        "\n",
        "    for i in range(1, max_dilation+1):\n",
        "      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n",
        "      temp = BatchNormalization()(temp)\n",
        "      a.append(temp)\n",
        "\n",
        "    x = Concatenate(axis= -1)(a)\n",
        "    x = Conv2D(nb_of_input_channels, kernel_size = (1,1), \n",
        "               strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "\n",
        "    input_tensor = x\n",
        "  \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckGzLkjGXJvX"
      },
      "source": [
        "def Shifter_Unit(input_tensor, nb_of_input_channels, max_dilation):\n",
        "    x1 = Conv2D(nb_of_input_channels*4, kernel_size = (1,1), \n",
        "                strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "\n",
        "    a = []\n",
        "\n",
        "    for i in range(1, max_dilation+1):\n",
        "      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), \n",
        "                             padding = 'same', activation= 'relu')(x1)\n",
        "      temp = MaxPool2D(pool_size=(2,2))(temp)\n",
        "      temp = BatchNormalization()(temp)\n",
        "      a.append(temp)\n",
        "\n",
        "    x = Concatenate(axis= -1)(a)\n",
        "\n",
        "    x = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcWQOMK6XKTO"
      },
      "source": [
        "def Network128(input_shape, nb_class, depth):\n",
        "  xin = Input(shape= input_shape)\n",
        "\n",
        "  x = Conv2D(16, kernel_size = (5,5), strides= (1,1), padding = 'same', activation='relu')(xin)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(32, kernel_size = (3,3), strides= (2,2), padding = 'same', activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "##Max Dilation rate will be vary in the range (1,5). \n",
        "\n",
        "# Max Dilation rate is 5 for tensor (64x64x32)\n",
        "  x = Residual_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5, number_of_units=depth)\n",
        "  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5)\n",
        "\n",
        "\n",
        "# Max Dilation rate is 4 for (32x32x64)\n",
        "  x = Residual_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4, number_of_units=depth)\n",
        "  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4)\n",
        "\n",
        "# Max Dilation rate is 3 for (16x16x128)\n",
        "  x = Residual_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3, number_of_units=depth)\n",
        "  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3)\n",
        "\n",
        "# Max Dilation rate is 2 for (8x8x256)\n",
        "  x = Residual_Unit(input_tensor=x, nb_of_input_channels=256, max_dilation=2, number_of_units=depth)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Dense(nb_class, activation= 'softmax')(x)\n",
        "\n",
        "  model = Model(xin, x)\n",
        "  opt= SGD(momentum=0.9)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXsmxVg5XYJI",
        "outputId": "5a914c31-772b-435f-be49-d6a3c5b52fec"
      },
      "source": [
        "from tensorflow import keras\n",
        "# model = Network128(input_shape = (img_h, img_w,1), nb_class = 8, depth = 2)\n",
        "# /content/drive/MyDrive/thermalimaging/models1/snapshot_model_6.h5\n",
        "model = keras.models.load_model('/content/drive/MyDrive/thermalimaging/models1/snapshot_model_6.h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 200, 200, 16) 416         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 100, 100, 32) 4640        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 100, 100, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 100, 100, 64) 2112        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 100, 100, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseConv (None, 100, 100, 64) 640         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_1 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_2 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_3 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_4 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 100, 100, 64) 256         depthwise_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 100, 100, 64) 256         depthwise_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 100, 100, 64) 256         depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 100, 100, 64) 256         depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 100, 100, 64) 256         depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 100, 100, 320 0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 100, 100, 32) 10272       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 100, 100, 32) 0           batch_normalization_8[0][0]      \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 100, 100, 64) 2112        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 100, 100, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_5 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_6 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_7 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_8 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_9 (DepthwiseCo (None, 100, 100, 64) 640         batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 100, 100, 64) 256         depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 100, 100, 64) 256         depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 100, 100, 64) 256         depthwise_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 100, 100, 64) 256         depthwise_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 100, 100, 64) 256         depthwise_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 100, 100, 320 0           batch_normalization_10[0][0]     \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 100, 100, 32) 10272       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 100, 100, 32) 128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 100, 100, 32) 0           batch_normalization_15[0][0]     \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 100, 100, 128 4224        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 100, 100, 128 512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_10 (DepthwiseC (None, 100, 100, 128 1280        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_11 (DepthwiseC (None, 100, 100, 128 1280        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_12 (DepthwiseC (None, 100, 100, 128 1280        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_13 (DepthwiseC (None, 100, 100, 128 1280        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_14 (DepthwiseC (None, 100, 100, 128 1280        batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 50, 50, 128)  0           depthwise_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 128)  0           depthwise_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 128)  0           depthwise_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 50, 50, 128)  0           depthwise_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 50, 50, 128)  0           depthwise_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 50, 50, 128)  512         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 50, 50, 128)  512         max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 50, 50, 128)  512         max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 50, 50, 128)  512         max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 50, 50, 128)  512         max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 50, 50, 640)  0           batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 50, 50, 64)   41024       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 50, 50, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 50, 50, 128)  8320        batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 50, 50, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_15 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_16 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_17 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_18 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 50, 50, 512)  0           batch_normalization_24[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 50, 50, 64)   32832       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 50, 50, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 50, 50, 64)   0           batch_normalization_28[0][0]     \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 50, 50, 128)  8320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 50, 50, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_19 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_20 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_21 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_22 (DepthwiseC (None, 50, 50, 128)  1280        batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 50, 50, 128)  512         depthwise_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 50, 50, 512)  0           batch_normalization_30[0][0]     \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 50, 50, 64)   32832       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 50, 50, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 50, 50, 64)   0           batch_normalization_34[0][0]     \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 50, 50, 256)  16640       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 50, 50, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_23 (DepthwiseC (None, 50, 50, 256)  2560        batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_24 (DepthwiseC (None, 50, 50, 256)  2560        batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_25 (DepthwiseC (None, 50, 50, 256)  2560        batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_26 (DepthwiseC (None, 50, 50, 256)  2560        batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 256)  0           depthwise_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 25, 25, 256)  0           depthwise_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 256)  0           depthwise_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 25, 25, 256)  0           depthwise_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 25, 25, 256)  1024        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 25, 25, 256)  1024        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 25, 25, 256)  1024        max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 25, 25, 256)  1024        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 25, 1024) 0           batch_normalization_36[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "                                                                 batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 128)  131200      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 25, 25, 128)  512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 256)  33024       batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 25, 25, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_27 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_28 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_29 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 25, 768)  0           batch_normalization_42[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 128)  98432       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 25, 25, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 25, 25, 128)  0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 25, 25, 256)  1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_30 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_31 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_32 (DepthwiseC (None, 25, 25, 256)  2560        batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 25, 25, 256)  1024        depthwise_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 25, 25, 768)  0           batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_48[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 128)  98432       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 25, 25, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 25, 25, 128)  0           batch_normalization_50[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 512)  66048       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 25, 25, 512)  2048        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_33 (DepthwiseC (None, 25, 25, 512)  5120        batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_34 (DepthwiseC (None, 25, 25, 512)  5120        batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_35 (DepthwiseC (None, 25, 25, 512)  5120        batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 512)  0           depthwise_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 12, 12, 512)  0           depthwise_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 12, 12, 512)  0           depthwise_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 512)  2048        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 512)  2048        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 512)  2048        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 12, 12, 1536) 0           batch_normalization_52[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 12, 12, 256)  393472      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 256)  1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 12, 12, 512)  131584      batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_36 (DepthwiseC (None, 12, 12, 512)  5120        batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_37 (DepthwiseC (None, 12, 12, 512)  5120        batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 512)  2048        depthwise_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 512)  2048        depthwise_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 12, 12, 1024) 0           batch_normalization_57[0][0]     \n",
            "                                                                 batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 12, 12, 256)  262400      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 256)  1024        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 12, 12, 256)  0           batch_normalization_59[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 12, 12, 512)  131584      add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 512)  2048        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_38 (DepthwiseC (None, 12, 12, 512)  5120        batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_39 (DepthwiseC (None, 12, 12, 512)  5120        batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 512)  2048        depthwise_conv2d_38[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 512)  2048        depthwise_conv2d_39[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 12, 12, 1024) 0           batch_normalization_61[0][0]     \n",
            "                                                                 batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 12, 12, 256)  262400      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 256)  1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 256)  0           batch_normalization_63[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 256)          0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          32896       global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 8)            520         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,992,648\n",
            "Trainable params: 1,967,208\n",
            "Non-trainable params: 25,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03yA2vRdXbVp"
      },
      "source": [
        "class SnapshotEnsemble(Callback):\n",
        "    # constructor\n",
        "    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
        "        self.epochs = n_epochs\n",
        "        self.cycles = n_cycles\n",
        "        self.lr_max = lrate_max\n",
        "        self.lrates = list()\n",
        "\n",
        "    \"\"\"\n",
        "    # calculate learning rate for epoch\n",
        "    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
        "        epochs_per_cycle = floor(n_epochs/n_cycles)\n",
        "        cos_inner = (pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
        "        return lrate_max/2 * (cos(cos_inner) + 1)\n",
        "\n",
        "    # calculate and set learning rate at the start of the epoch\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        # calculate learning rate\n",
        "        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
        "        # set learning rate\n",
        "        backend.set_value(self.model.optimizer.lr, lr)\n",
        "        # log value\n",
        "        self.lrates.append(lr)\n",
        "    \"\"\"\n",
        "    # save models at the end of each cycle\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # check if we can save model\n",
        "        epochs_per_cycle = floor(self.epochs / self.cycles)\n",
        "        if epoch != 0 and (epoch + 1) % epochs_per_cycle == 0:\n",
        "            # save model to file\n",
        "            filename = \"/content/drive/MyDrive/thermalimaging/snapshot_model_%d.h5\" % int((epoch + 1) / epochs_per_cycle)\n",
        "            self.model.save(filename)\n",
        "            print('>saved snapshot %s, epoch %d' % (filename, epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czLfzGfFXyIA"
      },
      "source": [
        "ca = SnapshotEnsemble(n_epochs, n_cycles, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2b4P8baYOzE"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        " \n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\t#test_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\t#test_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\t# define filename for this ensemble\n",
        "\t\tfilename = '/content/drive/MyDrive/thermalimaging/snapshot_model_' + str(i + 1) + '.h5'\n",
        "\t\t# load model from file\n",
        "\t\tmodel = load_model(filename)\n",
        "\t\t# add to list of members\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models\n",
        " \n",
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tsummed = numpy.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\tresult = argmax(summed, axis=1)\n",
        "\treturn result\n",
        " \n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "\t# select a subset of members\n",
        "\tsubset = members[:n_members]\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(subset, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)\n",
        " \n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n",
        "                                         factor=0.1,\n",
        "                                         patience=3,\n",
        "                                         cooldown=2,\n",
        "                                         min_lr=1e-9,\n",
        "                                         verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMDHZnu3Y3c3",
        "outputId": "e1b47348-2453-48ad-ea25-59a6a156858b"
      },
      "source": [
        "\n",
        "file_path=r'/content/drive/MyDrive/thermalimaging/IR_face_expr.csv'\n",
        "\n",
        "data=pd.read_csv(file_path)\n",
        "\n",
        "X= data.iloc[:,1:]  #features\n",
        "y= data.iloc[:,0]\n",
        "labels= list(map(int,y))\n",
        "\n",
        "X_full= np.array(X)\n",
        "y_full=np.array(y,dtype='int')\n",
        "\n",
        "X_full = X_full.reshape((X_full.shape[0], img_h, img_w, 1))\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_labels= to_categorical(y_full)\n",
        "\n",
        "\n",
        "print(\"Shape of X is = \",X_full.shape,\" and Shape of labels is =\",y_labels.shape)\n",
        "X_train= prep_pixels(X_full)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X is =  (1782, 200, 200, 1)  and Shape of labels is = (1782, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AszTniqTZ-Gu",
        "outputId": "9f063ac1-f05b-49c1-adfa-1faa7adbbc1a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X_train, y_labels, test_size=0.15, random_state=42)\n",
        "\n",
        "print(\"Shape of training data= \",Xtrain.shape,\" And labels= \",ytrain.shape)\n",
        "print(\"Shape of Validation data= \",Xtest.shape,\" And labels= \",ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data=  (1514, 200, 200, 1)  And labels=  (1514, 8)\n",
            "Shape of Validation data=  (268, 200, 200, 1)  And labels=  (268, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKepHDigNkRn"
      },
      "source": [
        "import sys \n",
        "import os\n",
        "sys.path.append(os.path.abspath(\"/content/drive/MyDrive/thermalimaging\"))\n",
        "import cosine_annealing  as cosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6yEVyxpONOT"
      },
      "source": [
        "\n",
        "#clr_triangular = cl.CyclicLR(step_size=(48*7),mode='triangular')\n",
        "clr = cosa.CosineAnnealingScheduler(T_max=100, eta_max=1e-2, eta_min=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0Yzlj-bDSE",
        "outputId": "7b2864b6-a8a4-4172-8d9a-96a1975f83c7"
      },
      "source": [
        "model.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), batch_size=batch_size,epochs=n_epochs, verbose=1, callbacks=[clr,ca])#ca]) #reduce_learning_rate])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 2/95 [..............................] - ETA: 35s - loss: 0.0015 - accuracy: 1.0000   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2030s vs `on_train_batch_end` time: 0.5597s). Check your callbacks.\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.9668 - val_accuracy: 0.8806\n",
            "Epoch 2/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0155 - accuracy: 0.9987 - val_loss: 1.0064 - val_accuracy: 0.8731\n",
            "Epoch 3/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.9926 - val_accuracy: 0.8843\n",
            "Epoch 4/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8806\n",
            "Epoch 5/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0332 - accuracy: 0.9967 - val_loss: 1.1206 - val_accuracy: 0.8284\n",
            "Epoch 6/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0409 - accuracy: 0.9927 - val_loss: 1.0862 - val_accuracy: 0.8209\n",
            "Epoch 7/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0710 - accuracy: 0.9894 - val_loss: 1.0535 - val_accuracy: 0.8321\n",
            "Epoch 8/500\n",
            "95/95 [==============================] - 78s 825ms/step - loss: 0.1076 - accuracy: 0.9742 - val_loss: 1.7458 - val_accuracy: 0.6940\n",
            "Epoch 9/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.1388 - accuracy: 0.9617 - val_loss: 0.8836 - val_accuracy: 0.8172\n",
            "Epoch 10/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.1144 - accuracy: 0.9789 - val_loss: 1.7846 - val_accuracy: 0.6716\n",
            "Epoch 11/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0938 - accuracy: 0.9828 - val_loss: 0.9374 - val_accuracy: 0.8060\n",
            "Epoch 12/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.1158 - accuracy: 0.9756 - val_loss: 1.1370 - val_accuracy: 0.7836\n",
            "Epoch 13/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0373 - accuracy: 0.9894 - val_loss: 0.8581 - val_accuracy: 0.8097\n",
            "Epoch 14/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0876 - accuracy: 0.9861 - val_loss: 0.7742 - val_accuracy: 0.8545\n",
            "Epoch 15/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0477 - accuracy: 0.9894 - val_loss: 0.9968 - val_accuracy: 0.8134\n",
            "Epoch 16/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.9488 - val_accuracy: 0.8582\n",
            "Epoch 17/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.1059 - accuracy: 0.9802 - val_loss: 1.1932 - val_accuracy: 0.7351\n",
            "Epoch 18/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.1861 - accuracy: 0.9557 - val_loss: 0.8884 - val_accuracy: 0.8134\n",
            "Epoch 19/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0769 - accuracy: 0.9822 - val_loss: 0.8076 - val_accuracy: 0.8657\n",
            "Epoch 20/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0427 - accuracy: 0.9901 - val_loss: 0.9773 - val_accuracy: 0.8172\n",
            "Epoch 21/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0341 - accuracy: 0.9927 - val_loss: 0.7567 - val_accuracy: 0.8694\n",
            "Epoch 22/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.7080 - val_accuracy: 0.8843\n",
            "Epoch 23/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.8411 - val_accuracy: 0.8881\n",
            "Epoch 24/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.8032 - val_accuracy: 0.8769\n",
            "Epoch 25/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.7363 - val_accuracy: 0.8806\n",
            "Epoch 26/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0525 - accuracy: 0.9908 - val_loss: 0.8622 - val_accuracy: 0.8694\n",
            "Epoch 27/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0302 - accuracy: 0.9934 - val_loss: 0.8180 - val_accuracy: 0.8731\n",
            "Epoch 28/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0400 - accuracy: 0.9921 - val_loss: 0.8603 - val_accuracy: 0.8507\n",
            "Epoch 29/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0203 - accuracy: 0.9967 - val_loss: 0.8691 - val_accuracy: 0.8619\n",
            "Epoch 30/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.8720 - val_accuracy: 0.8694\n",
            "Epoch 31/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.8495 - val_accuracy: 0.8769\n",
            "Epoch 32/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.8145 - val_accuracy: 0.8918\n",
            "Epoch 33/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.7885 - val_accuracy: 0.8993\n",
            "Epoch 34/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.8362 - val_accuracy: 0.8769\n",
            "Epoch 35/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.8782 - val_accuracy: 0.8769\n",
            "Epoch 36/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0312 - accuracy: 0.9967 - val_loss: 2.0398 - val_accuracy: 0.6978\n",
            "Epoch 37/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 1.0274 - val_accuracy: 0.8246\n",
            "Epoch 38/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.8806\n",
            "Epoch 39/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.8755 - val_accuracy: 0.8806\n",
            "Epoch 40/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.9886 - val_accuracy: 0.8582\n",
            "Epoch 41/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0201 - accuracy: 0.9987 - val_loss: 0.9939 - val_accuracy: 0.8731\n",
            "Epoch 42/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.9143 - val_accuracy: 0.8694\n",
            "Epoch 43/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.8712 - val_accuracy: 0.8769\n",
            "Epoch 44/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.8700 - val_accuracy: 0.8694\n",
            "Epoch 45/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.8694\n",
            "Epoch 46/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.8731\n",
            "Epoch 47/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0202 - accuracy: 0.9974 - val_loss: 0.9320 - val_accuracy: 0.8582\n",
            "Epoch 48/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.9233 - val_accuracy: 0.8657\n",
            "Epoch 49/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9517 - val_accuracy: 0.8657\n",
            "Epoch 50/500\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000>saved snapshot /content/drive/MyDrive/thermalimaging/snapshot_model_1.h5, epoch 49\n",
            "95/95 [==============================] - 80s 838ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.8657\n",
            "Epoch 51/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.8657\n",
            "Epoch 52/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 1.0656 - val_accuracy: 0.8507\n",
            "Epoch 53/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0252 - accuracy: 0.9974 - val_loss: 1.0126 - val_accuracy: 0.8545\n",
            "Epoch 54/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 1.0385 - val_accuracy: 0.8470\n",
            "Epoch 55/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.9935 - val_accuracy: 0.8545\n",
            "Epoch 56/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.9746 - val_accuracy: 0.8619\n",
            "Epoch 57/500\n",
            "95/95 [==============================] - 78s 825ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 0.9830 - val_accuracy: 0.8694\n",
            "Epoch 58/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 8.7554e-04 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.8657\n",
            "Epoch 59/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.9513 - val_accuracy: 0.8619\n",
            "Epoch 60/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 9.2025e-04 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.8619\n",
            "Epoch 61/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.9324 - val_accuracy: 0.8769\n",
            "Epoch 62/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 1.0331 - val_accuracy: 0.8582\n",
            "Epoch 63/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 6.3252e-04 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.8694\n",
            "Epoch 64/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 8.8977e-04 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.8731\n",
            "Epoch 65/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 8.2892e-04 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.8694\n",
            "Epoch 66/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.9668 - val_accuracy: 0.8769\n",
            "Epoch 67/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.9809 - val_accuracy: 0.8694\n",
            "Epoch 68/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.8657\n",
            "Epoch 69/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 8.0102e-04 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.8657\n",
            "Epoch 70/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.9700 - val_accuracy: 0.8731\n",
            "Epoch 71/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 6.4517e-04 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.8731\n",
            "Epoch 72/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.8769\n",
            "Epoch 73/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9945 - val_accuracy: 0.8731\n",
            "Epoch 74/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.9822 - val_accuracy: 0.8731\n",
            "Epoch 75/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 9.3287e-04 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.8731\n",
            "Epoch 76/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 5.5109e-04 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.8731\n",
            "Epoch 77/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.9922 - val_accuracy: 0.8694\n",
            "Epoch 78/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 9.0592e-04 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.8731\n",
            "Epoch 79/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 7.5890e-04 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 0.8731\n",
            "Epoch 80/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 5.2373e-04 - accuracy: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.8731\n",
            "Epoch 81/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.9896 - val_accuracy: 0.8769\n",
            "Epoch 82/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 6.6794e-04 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.8731\n",
            "Epoch 83/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 6.4032e-04 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.8731\n",
            "Epoch 84/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 5.6305e-04 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.8731\n",
            "Epoch 85/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.9912 - val_accuracy: 0.8769\n",
            "Epoch 86/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 6.5918e-04 - accuracy: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.8769\n",
            "Epoch 87/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.9867 - val_accuracy: 0.8769\n",
            "Epoch 88/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.9857 - val_accuracy: 0.8769\n",
            "Epoch 89/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 6.4008e-04 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.8769\n",
            "Epoch 90/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.8769\n",
            "Epoch 91/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 5.2375e-04 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8769\n",
            "Epoch 92/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.8769\n",
            "Epoch 93/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.8731\n",
            "Epoch 94/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 7.3561e-04 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.8731\n",
            "Epoch 95/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 8.2240e-04 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.8769\n",
            "Epoch 96/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 5.4441e-04 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.8769\n",
            "Epoch 97/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.9929 - val_accuracy: 0.8731\n",
            "Epoch 98/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 7.3464e-04 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.8769\n",
            "Epoch 99/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.8769\n",
            "Epoch 100/500\n",
            "95/95 [==============================] - ETA: 0s - loss: 6.6620e-04 - accuracy: 1.0000>saved snapshot /content/drive/MyDrive/thermalimaging/snapshot_model_2.h5, epoch 99\n",
            "95/95 [==============================] - 79s 835ms/step - loss: 6.6620e-04 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.8769\n",
            "Epoch 101/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 4.7327e-04 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.8769\n",
            "Epoch 102/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 9.7053e-04 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.8769\n",
            "Epoch 103/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.8769\n",
            "Epoch 104/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 8.3117e-04 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.8769\n",
            "Epoch 105/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.9917 - val_accuracy: 0.8769\n",
            "Epoch 106/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.8769\n",
            "Epoch 107/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 8.4315e-04 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.8769\n",
            "Epoch 108/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.8731\n",
            "Epoch 109/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 5.6737e-04 - accuracy: 1.0000 - val_loss: 0.9903 - val_accuracy: 0.8769\n",
            "Epoch 110/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 3.6067e-04 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.8769\n",
            "Epoch 111/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.9914 - val_accuracy: 0.8769\n",
            "Epoch 112/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 0.9922 - val_accuracy: 0.8769\n",
            "Epoch 113/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 5.0737e-04 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.8769\n",
            "Epoch 114/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 5.1947e-04 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.8769\n",
            "Epoch 115/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 8.9047e-04 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.8806\n",
            "Epoch 116/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 8.1354e-04 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.8806\n",
            "Epoch 117/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8806\n",
            "Epoch 118/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 4.1245e-04 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.8806\n",
            "Epoch 119/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 7.2632e-04 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.8806\n",
            "Epoch 120/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 6.3270e-04 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.8806\n",
            "Epoch 121/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 6.9613e-04 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.8769\n",
            "Epoch 122/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 7.1162e-04 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.8806\n",
            "Epoch 123/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 8.0081e-04 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.8806\n",
            "Epoch 124/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 5.9314e-04 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.8806\n",
            "Epoch 125/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 5.6762e-04 - accuracy: 1.0000 - val_loss: 0.9958 - val_accuracy: 0.8806\n",
            "Epoch 126/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 8.6304e-04 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.8806\n",
            "Epoch 127/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 5.6004e-04 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.8806\n",
            "Epoch 128/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 4.8366e-04 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.8806\n",
            "Epoch 129/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 6.7019e-04 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.8769\n",
            "Epoch 130/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.8769\n",
            "Epoch 131/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 5.8958e-04 - accuracy: 1.0000 - val_loss: 1.0057 - val_accuracy: 0.8806\n",
            "Epoch 132/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 7.3257e-04 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 0.8806\n",
            "Epoch 133/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 4.3226e-04 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.8806\n",
            "Epoch 134/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 4.8029e-04 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.8806\n",
            "Epoch 135/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.8806\n",
            "Epoch 136/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 3.5001e-04 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.8806\n",
            "Epoch 137/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 5.5071e-04 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.8769\n",
            "Epoch 138/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 6.7743e-04 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.8806\n",
            "Epoch 139/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 7.3993e-04 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.8806\n",
            "Epoch 140/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.9824 - val_accuracy: 0.8843\n",
            "Epoch 141/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 5.8276e-04 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.8881\n",
            "Epoch 142/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 8.9032e-04 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.8806\n",
            "Epoch 143/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 6.1663e-04 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.8769\n",
            "Epoch 144/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.8694\n",
            "Epoch 145/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 3.3757e-04 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.8731\n",
            "Epoch 146/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 0.9745 - val_accuracy: 0.8694\n",
            "Epoch 147/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 1.0098 - val_accuracy: 0.8657\n",
            "Epoch 148/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.0187 - val_accuracy: 0.8769\n",
            "Epoch 149/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 4.3477e-04 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.8769\n",
            "Epoch 150/500\n",
            "95/95 [==============================] - ETA: 0s - loss: 6.4395e-04 - accuracy: 1.0000>saved snapshot /content/drive/MyDrive/thermalimaging/snapshot_model_3.h5, epoch 149\n",
            "95/95 [==============================] - 80s 839ms/step - loss: 6.4395e-04 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.8657\n",
            "Epoch 151/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 4.7146e-04 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.8694\n",
            "Epoch 152/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 4.4150e-04 - accuracy: 1.0000 - val_loss: 0.9866 - val_accuracy: 0.8694\n",
            "Epoch 153/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 4.0595e-04 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.8731\n",
            "Epoch 154/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 4.4235e-04 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.8657\n",
            "Epoch 155/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.0326 - val_accuracy: 0.8769\n",
            "Epoch 156/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 1.0225 - val_accuracy: 0.8806\n",
            "Epoch 157/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 5.4137e-04 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8657\n",
            "Epoch 158/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.0809 - val_accuracy: 0.8694\n",
            "Epoch 159/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 8.2845e-04 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.8657\n",
            "Epoch 160/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.1433 - val_accuracy: 0.8657\n",
            "Epoch 161/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.0650 - val_accuracy: 0.8694\n",
            "Epoch 162/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 1.1005 - val_accuracy: 0.8657\n",
            "Epoch 163/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0142 - accuracy: 0.9993 - val_loss: 1.0925 - val_accuracy: 0.8806\n",
            "Epoch 164/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 1.0489 - val_accuracy: 0.8657\n",
            "Epoch 165/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.1023 - val_accuracy: 0.8769\n",
            "Epoch 166/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 5.0277e-04 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.8806\n",
            "Epoch 167/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 7.3473e-04 - accuracy: 1.0000 - val_loss: 1.1386 - val_accuracy: 0.8769\n",
            "Epoch 168/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 5.1534e-04 - accuracy: 1.0000 - val_loss: 1.1384 - val_accuracy: 0.8806\n",
            "Epoch 169/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 6.8040e-04 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.8769\n",
            "Epoch 170/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 6.4644e-04 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.8731\n",
            "Epoch 171/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 5.8056e-04 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.8731\n",
            "Epoch 172/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0025 - accuracy: 0.9980 - val_loss: 1.0631 - val_accuracy: 0.8806\n",
            "Epoch 173/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.0439 - val_accuracy: 0.8806\n",
            "Epoch 174/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 7.4543e-04 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.8769\n",
            "Epoch 175/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0154 - accuracy: 0.9987 - val_loss: 1.1669 - val_accuracy: 0.8545\n",
            "Epoch 176/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 1.0512 - val_accuracy: 0.8582\n",
            "Epoch 177/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 1.3133 - val_accuracy: 0.8209\n",
            "Epoch 178/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.8507\n",
            "Epoch 179/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.2784 - val_accuracy: 0.7799\n",
            "Epoch 180/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0506 - accuracy: 0.9914 - val_loss: 1.2426 - val_accuracy: 0.8209\n",
            "Epoch 181/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0342 - accuracy: 0.9947 - val_loss: 0.9294 - val_accuracy: 0.8396\n",
            "Epoch 182/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.8036 - val_accuracy: 0.8769\n",
            "Epoch 183/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.7391 - val_accuracy: 0.8806\n",
            "Epoch 184/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0326 - accuracy: 0.9934 - val_loss: 1.2367 - val_accuracy: 0.7910\n",
            "Epoch 185/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0453 - accuracy: 0.9927 - val_loss: 0.8741 - val_accuracy: 0.8545\n",
            "Epoch 186/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 1.0076 - val_accuracy: 0.8172\n",
            "Epoch 187/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0326 - accuracy: 0.9908 - val_loss: 0.9071 - val_accuracy: 0.8358\n",
            "Epoch 188/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0270 - accuracy: 0.9967 - val_loss: 0.8204 - val_accuracy: 0.8545\n",
            "Epoch 189/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0574 - accuracy: 0.9868 - val_loss: 2.6686 - val_accuracy: 0.6381\n",
            "Epoch 190/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0945 - accuracy: 0.9828 - val_loss: 0.8906 - val_accuracy: 0.8507\n",
            "Epoch 191/500\n",
            "95/95 [==============================] - 79s 833ms/step - loss: 0.0362 - accuracy: 0.9934 - val_loss: 0.9628 - val_accuracy: 0.8321\n",
            "Epoch 192/500\n",
            "95/95 [==============================] - 79s 832ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 1.0845 - val_accuracy: 0.7873\n",
            "Epoch 193/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 0.8597 - val_accuracy: 0.8769\n",
            "Epoch 194/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0548 - accuracy: 0.9875 - val_loss: 0.8307 - val_accuracy: 0.8470\n",
            "Epoch 195/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0902 - accuracy: 0.9802 - val_loss: 0.8052 - val_accuracy: 0.8545\n",
            "Epoch 196/500\n",
            "95/95 [==============================] - 78s 826ms/step - loss: 0.1102 - accuracy: 0.9749 - val_loss: 0.9497 - val_accuracy: 0.7799\n",
            "Epoch 197/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0697 - accuracy: 0.9868 - val_loss: 0.7380 - val_accuracy: 0.8731\n",
            "Epoch 198/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0723 - accuracy: 0.9828 - val_loss: 0.9004 - val_accuracy: 0.8209\n",
            "Epoch 199/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0641 - accuracy: 0.9835 - val_loss: 0.8591 - val_accuracy: 0.8396\n",
            "Epoch 200/500\n",
            "95/95 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9901>saved snapshot /content/drive/MyDrive/thermalimaging/snapshot_model_4.h5, epoch 199\n",
            "95/95 [==============================] - 80s 843ms/step - loss: 0.0530 - accuracy: 0.9901 - val_loss: 0.7944 - val_accuracy: 0.8507\n",
            "Epoch 201/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0258 - accuracy: 0.9947 - val_loss: 0.7082 - val_accuracy: 0.8582\n",
            "Epoch 202/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.9264 - val_accuracy: 0.8321\n",
            "Epoch 203/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0593 - accuracy: 0.9861 - val_loss: 1.3266 - val_accuracy: 0.7836\n",
            "Epoch 204/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0700 - accuracy: 0.9848 - val_loss: 0.9024 - val_accuracy: 0.8396\n",
            "Epoch 205/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0685 - accuracy: 0.9828 - val_loss: 1.0574 - val_accuracy: 0.7799\n",
            "Epoch 206/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.1182 - accuracy: 0.9683 - val_loss: 1.3527 - val_accuracy: 0.7164\n",
            "Epoch 207/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0733 - accuracy: 0.9835 - val_loss: 0.9553 - val_accuracy: 0.8022\n",
            "Epoch 208/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0938 - accuracy: 0.9848 - val_loss: 1.0102 - val_accuracy: 0.7948\n",
            "Epoch 209/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0615 - accuracy: 0.9848 - val_loss: 0.8999 - val_accuracy: 0.8209\n",
            "Epoch 210/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0273 - accuracy: 0.9947 - val_loss: 0.8592 - val_accuracy: 0.8284\n",
            "Epoch 211/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.7742 - val_accuracy: 0.8507\n",
            "Epoch 212/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.7849 - val_accuracy: 0.8507\n",
            "Epoch 213/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.7853 - val_accuracy: 0.8769\n",
            "Epoch 214/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.8211 - val_accuracy: 0.8619\n",
            "Epoch 215/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.9385 - val_accuracy: 0.8657\n",
            "Epoch 216/500\n",
            "95/95 [==============================] - 79s 827ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.7835 - val_accuracy: 0.8582\n",
            "Epoch 217/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0470 - accuracy: 0.9875 - val_loss: 0.8851 - val_accuracy: 0.8769\n",
            "Epoch 218/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0687 - accuracy: 0.9855 - val_loss: 0.6969 - val_accuracy: 0.8507\n",
            "Epoch 219/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.8725 - val_accuracy: 0.8134\n",
            "Epoch 220/500\n",
            "95/95 [==============================] - 79s 834ms/step - loss: 0.0503 - accuracy: 0.9908 - val_loss: 0.6551 - val_accuracy: 0.8731\n",
            "Epoch 221/500\n",
            "95/95 [==============================] - 79s 829ms/step - loss: 0.0316 - accuracy: 0.9934 - val_loss: 0.7013 - val_accuracy: 0.8731\n",
            "Epoch 222/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 1.1129 - val_accuracy: 0.7799\n",
            "Epoch 223/500\n",
            "95/95 [==============================] - 79s 828ms/step - loss: 0.0394 - accuracy: 0.9947 - val_loss: 0.7551 - val_accuracy: 0.8582\n",
            "Epoch 224/500\n",
            "95/95 [==============================] - 79s 830ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.7978 - val_accuracy: 0.8545\n",
            "Epoch 225/500\n",
            "95/95 [==============================] - 79s 831ms/step - loss: 0.0298 - accuracy: 0.9941 - val_loss: 0.8904 - val_accuracy: 0.8284\n",
            "Epoch 226/500\n",
            "80/95 [========================>.....] - ETA: 12s - loss: 0.0183 - accuracy: 0.9945"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZL9N75NThVJ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DEYiXb-Uqkg"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvTTovRbVzzz"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Fp8qoGW9Db"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUgbmreQYGSz"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WLdh8oAZPig"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA8Xf1J1aYxy"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9XhcI3zbiBS"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op7M9JRucrQ0"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adhJysJZd0gU"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6XKMIUe9vy"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uqab3hUgG_W"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmquFszQhQOv"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G9nqmMOiZeU"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUkSvn3vji3m"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqdhjmM0ksHE"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2vnQl-0l1WX"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZJGN6E2m-1r"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yITqExMkoIFL"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeUUL3GppRE6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh7MZ9YqaUk"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8cYh9pWrjaj"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDDiagFHssp1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbWAI3Knt15S"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxbQw7QHu_JN"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAzQFOeqwIYP"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnC-TQlyxRny"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wrZYtiyya3S"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D53v6fLdzkHS"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIyInM9K0tWS"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjZqTAru12lw"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2NWTUgx2_1P"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHhEsi_S4JEy"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzYZFXP5SUt"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLzZ6HHk6bjx"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "momdBAXb7kzs"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3jOzndY8uDQ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLxuu-0f93SQ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkwkCW7j_AiK"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMaDaUrrAJxR"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7NK0VmJBTA4"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqC3IaglCcQh"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmPxCpZkDlf_"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx1l1nULEuvZ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx7M8TIAF3_O"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnhemmqAHBOZ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIF_8lDGJOJQ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux-B6DcbKXYz"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_DMW5dkLgoV"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgM3l8QlMp30"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxQoKvf3NzHU"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSRte2wSO8W1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoHj5jS-QFmW"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82TMQrSLRO10"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUrVsQewSYO2"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roB5Np5GG7qV"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU0LWm0TcBar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}